# Seoul Attractions Web Scraper

This is a Python web scraper tool for collecting information about Seoul tourist attractions. The scraper retrieves data from the [Visit Seoul official website](https://english.visitseoul.net/attractions), including names, links, descriptions, and transportation information.

## Features

- Automatically scrapes all Seoul tourist attractions
- Supports pagination
- Scrapes detail pages for descriptions and transportation information
- Saves results in JSON format
- Built-in friendly delay mechanism to avoid excessive load on the target website

## Dependencies

- requests: Handling HTTP requests
- BeautifulSoup4: Parsing HTML content
- re: Using regular expressions
- json: Processing JSON data
- urllib.parse: Processing URLs

## Installation

1. Ensure your system has Python 3.6+ installed
2. Install required dependencies:

```bash
pip install requests beautifulsoup4
```

## Usage

1. Run the scraper script:

```bash
python seoul_scraper.py
```

2. The program will begin collecting data and display progress information in the console
3. Upon completion, the scraped data will be saved to the `seoul_attractions.json` file

## Output Data Format

The JSON file generated by the scraper contains the following fields:

- `page`: The page number where the attraction was found
- `name`: Attraction name
- `link`: Link to the attraction's detail page
- `description`: Attraction description
- `transport`: Transportation information

## Notes

- This scraper is for learning and research purposes only
- Please control the scraping frequency reasonably to avoid burdening the target website
- Respect the website's robots.txt rules and terms of use 
