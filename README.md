Seoul Attractions Web Scraper
This is a Python scraper tool used to crawl information about tourist attractions in Seoul. The scraper retrieves attraction data from the official Visit Seoul website, including names, links, descriptions, and transportation information.
Features
Automatically crawls information for all tourist attractions in Seoul
Supports pagination crawling
Crawls detail pages to get attraction descriptions and transportation information
Saves results in JSON format
Includes a built-in polite delay mechanism to avoid excessive load on the target website
Dependencies
requests: For handling HTTP requests
BeautifulSoup4: For parsing HTML content
re: For using regular expressions
json: For handling JSON data
urllib.parse: For handling URLs
Installation
Ensure you have Python 3.6+ installed on your system.
Install the required dependencies:
pip install requests beautifulsoup4
Use code with caution.
Bash
Usage
Run the scraper script:
python seoul_scraper.py
Use code with caution.
Bash
The program will start crawling data and display progress information in the console.
Once completed, the crawled data will be saved to the seoul_attractions.json file.
Output Data Format
The JSON file generated by the scraper includes the following fields:
page: The page number where the attraction was found
name: The name of the attraction
link: The link to the attraction's detail page
description: The description of the attraction
transport: Transportation information
Notes
This scraper is intended for learning and research purposes only.
Please control the crawling frequency reasonably to avoid burdening the target website.
Respect the website's robots.txt rules and terms of use.
